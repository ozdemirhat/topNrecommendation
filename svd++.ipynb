{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import svds\n",
    "import pickle\n",
    "import surprise as srp\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to dataset file\n",
    "#file_path = os.path.expanduser('~/.surprise_data/ml-100k/ml-100k/u.data')\n",
    "\n",
    "# As we're loading a custom dataset, we need to define a reader. In the\n",
    "# movielens-100k dataset, each line has the following format:\n",
    "# 'user item rating timestamp', separated by '\\t' characters.\n",
    "# and split it into 3 folds for cross-validation.\n",
    "reader = srp.Reader(line_format='user item rating timestamp', sep=',')\n",
    "\n",
    "data = srp.Dataset.load_from_file('data/training.dat', reader=reader)\n",
    "data.split(n_folds=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use the famous SVD algorithm.\n",
    "algo = srp.SVD()\n",
    "\n",
    "for trainset, testset in data.folds():\n",
    "\n",
    "    # train and test algorithm.\n",
    "    algo.train(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "\n",
    "    # Compute and print Root Mean Squared Error\n",
    "    rmse = srp.accuracy.rmse(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = str(1)  # raw user id (as in the ratings file). They are **strings**!\n",
    "iid = str(48)  # raw item id (as in the ratings file). They are **strings**!\n",
    "\n",
    "# get a prediction for specific users and items.\n",
    "pred = algo.predict(uid, iid, r_ui=4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = algo.predict(uid, iid, r_ui=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = algo.predict(uid, iid, r_ui=1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = algo.predict(uid, iid, r_ui=0, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = pd.read_table('data/test.csv', sep = ',', header=None, engine='python')\n",
    "print(test_file.shape)\n",
    "movie_file = pd.read_table('ml-1m/movies.dat', sep = '::', header=None, engine='python')\n",
    "print(movie_file.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movies 3666(gercege karşılık gelen index) alıp 3952(gerçekid) döner, movie_indices 3952 alıp 3666 döner\n",
    "test_users = np.unique(test_file[0]) # 1(0.idex) den 6040(6039.index) a kadar\n",
    "movies = np.unique(movie_file[0])\n",
    "\n",
    "test_number_of_rows = len(test_users) #6040\n",
    "number_of_columns = len(movies) #3667\n",
    "\n",
    "movie_indices, test_user_indices = {}, {}\n",
    " \n",
    "for i in range(len(movies)):\n",
    "    movie_indices[movies[i]] = i # movie_indices[3952] = 3666 x.filmin indisini verir\n",
    "  \n",
    "for i in range(len(test_users)):\n",
    "    test_user_indices[test_users[i]] = i # x.userın indisini verir\n",
    "print(len(movie_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_V = sp.lil_matrix((test_number_of_rows, number_of_columns))\n",
    "for line in test_file.values:\n",
    "    u, i , r , t = map(int,line)\n",
    "    test_V[test_user_indices[u], movie_indices[i]] = r # gerçek user ve movie idnin indexini bulup ratingi matrixteki yere atar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P = sp.lil_matrix((test_number_of_rows, number_of_columns))\n",
    "#for user in range(test_number_of_rows):\n",
    "#    for movie in np.nonzero(test_V[user,:])[1]:\n",
    "#        pred = algo.predict(str(test_users[user]), str(movies[movie]), r_ui=0, verbose=False)\n",
    "#        P[user, movie] = pred[3]\n",
    "#P = P.todense()\n",
    "#print(P.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(index):\n",
    "    result = sp.lil_matrix((1, number_of_columns))\n",
    "    for movie in np.nonzero(test_V[index,:])[1]:\n",
    "        pred = algo.predict(str(test_users[index]), str(movies[movie]), r_ui=0, verbose=False)\n",
    "        result[0, movie] = pred[3]\n",
    "    return result.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(index):\n",
    "    P = predict(index)\n",
    "    indexList = np.nonzero(P[0,:])[1]\n",
    "    relevant = np.asarray(P[0,indexList])\n",
    "    #print(\"indexlist\", indexList)\n",
    "    #print(\"relevant\", relevant)\n",
    "    indexSort = np.fliplr(relevant.argsort())\n",
    "    #print(\"indexsort\", indexSort)\n",
    "    result = []\n",
    "    for i in indexSort[0]:\n",
    "        result.append(movies[indexList[i]])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = recommend(0)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisionAt = 5\n",
    "def computeUserAccuracy(index):\n",
    "    computedMovies = recommend(index)\n",
    "    if not computedMovies:\n",
    "        return 0\n",
    "    weightedSum = 0\n",
    "    counter = 0\n",
    "    if precisionAt > len(computedMovies):\n",
    "        counter = len(computedMovies) \n",
    "    else:\n",
    "        counter = precisionAt \n",
    "    sumWeight = (counter * (counter +1)) /2\n",
    "    for recommendation in computedMovies:\n",
    "        if (counter != 0):\n",
    "            weightedSum = weightedSum + test_V[index, movie_indices[recommendation]] * counter\n",
    "            counter = counter - 1  \n",
    "    return float(weightedSum / (sumWeight*5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAccuracy():\n",
    "    empty = 0\n",
    "    sumUserAccuracy = 0.0\n",
    "    for user in range(0,test_V.shape[0]):\n",
    "        userAccuracy = computeUserAccuracy(user)\n",
    "        if (userAccuracy == 0):\n",
    "            empty = empty + 1\n",
    "        sumUserAccuracy = sumUserAccuracy + userAccuracy\n",
    "        print(userAccuracy)\n",
    "    print(empty)\n",
    "    print(float(sumUserAccuracy / (test_V.shape[0] - empty)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeUserAccuracy(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
