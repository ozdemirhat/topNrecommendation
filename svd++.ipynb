{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import svds\n",
    "import pickle\n",
    "import surprise as srp\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to dataset file\n",
    "#file_path = os.path.expanduser('~/.surprise_data/ml-100k/ml-100k/u.data')\n",
    "\n",
    "# As we're loading a custom dataset, we need to define a reader. In the\n",
    "# itemlens-100k dataset, each line has the following format:\n",
    "# 'user item rating timestamp', separated by '\\t' characters.\n",
    "# and split it into 3 folds for cross-validation.\n",
    "reader = srp.Reader(line_format='user item rating timestamp', sep=',')\n",
    "\n",
    "data = srp.Dataset.load_from_file('data/training.dat', reader=reader)\n",
    "data.split(n_folds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use the famous SVD algorithm.\n",
    "#algo = srp.SVD(n_factors=16)\n",
    "\n",
    "#sim_options = {'name': 'pearson_baseline', 'user_based': False}\n",
    "#algo = srp.KNNBaseline(sim_options=sim_options)\n",
    "\n",
    "algo = srp.NormalPredictor()\n",
    "\n",
    "for trainset, testset in data.folds():\n",
    "\n",
    "    # train and test algorithm.\n",
    "    algo.train(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "\n",
    "    # Compute and print Root Mean Squared Error\n",
    "    #rmse = srp.accuracy.rmse(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = str(1)  # raw user id (as in the ratings file). They are **strings**!\n",
    "iid = str(48)  # raw item id (as in the ratings file). They are **strings**!\n",
    "\n",
    "# get a prediction for specific users and items.\n",
    "pred = algo.predict(uid, iid, r_ui=4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = pd.read_table('data/test.csv', sep=',', header=None, engine='python')\n",
    "print(test_file.shape)\n",
    "item_file = pd.read_table('ml-1m/movies.dat', sep='::', header=None, engine='python')\n",
    "print(item_file.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# items 3666(gercege karşılık gelen index) alıp 3952(gerçekid) döner, itemIndices 3952 alıp 3666 döner\n",
    "testUsers = np.unique(test_file[0])  # 1(0.idex) den 6040(6039.index) a kadar\n",
    "items = np.unique(item_file[0])\n",
    "\n",
    "testNumberOfUsers = len(testUsers)  # 6040\n",
    "numberOfItems = len(items)  # 3667\n",
    "\n",
    "itemIndices, testUserIndices = {}, {}\n",
    "\n",
    "for i in range(len(items)):\n",
    "    # itemIndices[3952] = 3666 x.filmin indisini verir\n",
    "    itemIndices[items[i]] = i\n",
    "\n",
    "for i in range(len(testUsers)):\n",
    "    testUserIndices[testUsers[i]] = i  # x.userın indisini verir\n",
    "print(len(itemIndices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testV = sp.lil_matrix((testNumberOfUsers, numberOfItems))\n",
    "for line in test_file.values:\n",
    "    u, i, r, t = map(int, line)\n",
    "    # gerçek user ve item idnin indexini bulup ratingi matrixteki yere atar\n",
    "    testV[testUserIndices[u], itemIndices[i]] = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(index):\n",
    "    result = sp.lil_matrix((1, numberOfItems))\n",
    "    for item in np.nonzero(testV[index, :])[1]:\n",
    "        pred = algo.predict(str(testUsers[index]), str(items[item]), r_ui=0, verbose=False)\n",
    "        result[0, item] = pred[3]\n",
    "    return result.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(index):\n",
    "    P = predict(index)\n",
    "    indexList = np.nonzero(P[0, :])[1]\n",
    "    relevant = np.asarray(P[0, indexList])\n",
    "    #print(\"indexlist\", indexList)\n",
    "    #print(\"relevant\", relevant)\n",
    "    indexSort = np.fliplr(relevant.argsort())\n",
    "    #print(\"indexsort\", indexSort)\n",
    "    result = []\n",
    "    for i in indexSort[0]:\n",
    "        result.append(items[indexList[i]])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = recommend(0)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisionAt = 5\n",
    "\n",
    "\n",
    "def computeUserAccuracy(index):\n",
    "    computeditems = recommend(index)\n",
    "    if not computeditems:\n",
    "        return 0\n",
    "    weightedSum = 0\n",
    "    counter = 0\n",
    "    if precisionAt > len(computeditems):\n",
    "        counter = len(computeditems)\n",
    "    else:\n",
    "        counter = precisionAt\n",
    "    sumWeight = (counter * (counter + 1)) / 2\n",
    "    for recommendation in computeditems:\n",
    "        if (counter != 0):\n",
    "            weightedSum = weightedSum + testV[index, itemIndices[recommendation]] * counter\n",
    "            counter = counter - 1\n",
    "    return float(weightedSum / (sumWeight * 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAccuracy():\n",
    "    empty = 0\n",
    "    sumUserAccuracy = 0.0\n",
    "    for user in range(0, testV.shape[0]):\n",
    "        userAccuracy = computeUserAccuracy(user)\n",
    "        if (userAccuracy == 0):\n",
    "            empty = empty + 1\n",
    "        sumUserAccuracy = sumUserAccuracy + userAccuracy\n",
    "        print(userAccuracy)\n",
    "    print(empty)\n",
    "    print(float(sumUserAccuracy / (testV.shape[0] - empty)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeUserAccuracy(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
